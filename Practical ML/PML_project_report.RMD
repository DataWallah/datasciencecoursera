---
title: "PML Project"
output: html_document
---

### Practical Machine Learning Project (June 2014)

### Introduction

This is the required report for the 'Practical Machine Learning' project. It describes a predictive model built using a collection of personal activity data, and the results of applying a test set of to the model to get predictions.

More details on the experiment that resulted in this data can be found here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

In the code below I have used the eval=FALSE option in some chunks so as to suppress evaluation, as it takes a long time and I have already run the analyses. I loaded up my prior analysis so as to print the results.


```{r,echo=FALSE,cache=TRUE}
load("C:/KK Stuff/KKLaptop-1 Stuff/KK Stuff (New)/Courses/DS Practical ML/ML Project/.RData")
options(digits=4,warn=-1)
```

```{r,echo=FALSE}
#
# Practical Machine Learning Project
#
# Background
# Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a
# large amount of data about personal activity relatively inexpensively. These type of devices
# are part of the quantified self movement - a group of enthusiasts who take measurements about 
# themselves regularly to improve their health, to find patterns in their behavior, 
# or because they are tech geeks. One thing that people regularly do is quantify how much of 
# a particular activity they do, but they rarely quantify how well they do it. In this project, 
# your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 
# participants. They were asked to perform barbell lifts correctly and incorrectly in 5 
# different ways. More information is available from the website here: 
# http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). 
#
# Data 
#
# The training data for this project are available here: 
# https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
# The test data are available here: 
# https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv
# The data for this project come from this source: http://groupware.les.inf.puc-rio.br/har. 
# If you use the document you create for this class for any purpose please cite them as they 
# have been very generous in allowing their data to be used for this kind of assignment. 
#
# What you should submit
# The goal of your project is to predict the manner in which they did the exercise. This is the 
# "classe" variable in the training set. You may use any of the other variables to predict with. 
# You should create a report describing how you built your model, how you used cross validation, 
# what you think the expected out of sample error is, and why you made the choices you did. 
# You will also use your prediction model to predict 20 different test cases.

setwd("C:/KK Stuff/KKLaptop-1 Stuff/KK Stuff (New)/Courses/DS Practical ML/ML Project")
```

### Data Load

Data used for this project were downloaded into a local directory from:  
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv  
and  
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

Let's first load up the data from the local directory:

```{r,echo=TRUE,cache=TRUE,eval=FALSE}
trn<-read.csv("pml-training.csv")
tst<-read.csv("pml-testing.csv")
```

### Data Transformation

Inspection of the data using the summary function showed that the first seven variables in each dataset contained identification information not relevant to the analysis or prediction model. So we remove them. We also remove a number of variables with no values in them (all NAs), as they clearly have no predictive value. The remaining variables all report data from the activity monitors.

```{r,echo=TRUE,eval=FALSE}
trn<-trn[,-c(1:7)]
tst<-tst[,-c(1:7)]
# Summary of the data shows several columns with only NAs in the training set
# Remove those columns from training
colsNA <- apply(trn,2,function(x) {sum(is.na(x))})
trn<-trn[,which(colsNA==0)]
# and from the test set
tst<-tst[,which(colsNA==0)]
```

Since we have such a large data set, let's take a random sample of 20% of the training set with the selection based on the distribution of the response variable (classe) in the training set.

```{r,echo=TRUE,eval=FALSE}
# Train a simple tree with cross-validation
# Use a small sample (20%) to reduce compute time for CV tree
library(caTools)
set.seed(123)
split = sample.split(trn$classe, SplitRatio = 0.2)
tr1 = subset(trn, split==TRUE)
```

### Build the model

We will build a simple tree model using randomForest, as this is the easiest and usually very accurate. We have cleaned up our data, and we can now just run the model with cross-validation with 3 folds. Note that we are predicting the 'classe' variable, using all the other variables in the cleaned up data.

```{r,echo=TRUE,eval=FALSE}
# Train a simple tree with cross-validation
library(caret)
fC1<-trainControl(method="repeatedcv",number=3, repeats=3,verboseIter=TRUE, allowParallel=TRUE)
rf1<-train(classe~.,method="rf",data=tr1,trControl=fC1)
```
```{r}
rf1
```
 

The model report shows us the accuracy of the model is 95.9%, so we don't need to build any more models. We can apply the model to the training set, and take a look at the accuracy.


```{r,cache=TRUE}
# check the accuracy on the training set
library(caret)
prf1<-predict(rf1,newdata=trn[,1:85])
confusionMatrix(trn$classe,prf1)
```
    

And we can see from the confusion matrix statistics that the prediction accuracy is 97.83%. This suggests there is some over-fitting going on, however it is beyond the scope of this project to actually remove variables to build a realistic model. 

We would expect the out-of-sample accuracy of the model to be below 97.83%, to account for overfitting in the model. Note that the model built by the experiment designers resulted in out-of-sample accuracy of between 70% and 80%.

### Prediction on Test Set

We now apply the model to the test data.

```{r,cache=TRUE,eval=FALSE}
# predict using the test set
prf1ts1<-predict(rf1,newdata=tst[,1:85])
```

```{r,echo=FALSE,eval=FALSE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}
pml_write_files(prf1ts1)
```

Predicted data was applied to the course submission page, and the accuracy of the predictions was 100%. This is not surprising, as 1) the model is overfitted and 2) the size of test set is very small compared to the size of the training set.